{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 1:\n",
        "\n",
        "Escriba ejemplos de frase o busque ejemplos de párrafos de texto con diferentes estructuras, palabras y signos de puntuación. Utilice los códigos de One-Hot Encoding en las dos versiones que presenta el material expuesto en clase. Analice los resultados."
      ],
      "metadata": {
        "id": "bM2sPewkfdCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D337qe8XfYUp"
      },
      "outputs": [],
      "source": [
        "#importo las librerias necesarias\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Mis frases que luego divido en palabras\n",
        "fraseUno = \"Estaba en llamas cuando me acosté.\"\n",
        "fraseDos = \"La guitarra es un instrumento musical.\"\n",
        "\n",
        "palabrasUno = fraseUno.split()\n",
        "palabrasDos = fraseDos.split()\n",
        "\n",
        "#-----------Primera-Frase--------------------------------------------------------------------------\n",
        "\n",
        "#OneHotEncoding con OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "onehot_encodedUno = onehot_encoder.fit_transform(np.array(palabrasUno).reshape(-1, 1))\n",
        "\n",
        "print(onehot_encodedUno)\n",
        "\n",
        "for i, palabra in enumerate(palabrasUno):\n",
        "    print(f\"La palabra '{palabra}' se codificó como: {onehot_encodedUno[i]}\")\n",
        "\n",
        "#OneHotEncoding con pandas\n",
        "dataFrame = pd.DataFrame(palabrasUno, columns=['Palabras'])\n",
        "\n",
        "onehot_encodedDos = pd.get_dummies(dataFrame['Palabras'])\n",
        "\n",
        "print(onehot_encodedDos)\n",
        "\n",
        "for i, palabra in enumerate(palabrasUno):\n",
        "    print(f\"La palabra '{palabra}' se codificó como: {onehot_encodedDos.iloc[i].to_numpy()}\")\n",
        "\n",
        "#-----------Segunda-Frase--------------------------------------------------------------------------\n",
        "\n",
        "#OneHotEncoding con OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "onehot_encodedUno = onehot_encoder.fit_transform(np.array(palabrasDos).reshape(-1, 1))\n",
        "\n",
        "print(onehot_encodedUno)\n",
        "\n",
        "for i, palabra in enumerate(palabrasDos):\n",
        "    print(f\"La palabra '{palabra}' se codifió como: {onehot_encodedUno[i]}\")\n",
        "\n",
        "#OneHotEncoding con pandas\n",
        "dataFrame = pd.DataFrame(palabrasDos, columns=['Palabras'])\n",
        "\n",
        "onehot_encodedDos = pd.get_dummies(dataFrame['Palabras'])\n",
        "\n",
        "print(onehot_encodedDos)\n",
        "\n",
        "for i, palabra in enumerate(palabrasDos):\n",
        "    print(f\"La palbra '{palabra}' se codificó como: {onehot_encodedDos.iloc[i].to_numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 2:\n",
        "\n",
        "De los recursos propuestos en el último ejercicio de la unidad 1 con el texto obtenido del documento PROYECTO DE LEY TURISMO SOCIAL 2004.pdf y el texto de la metodología en la extracción de webscrapping del ministerio de turismo.\n",
        "\n",
        "Utilizar las bibliotecas de procesamiento de texto en python para representar estos documentos en forma de matrices numéricas utilizando tanto CountVectorizer como TfidfVectorizer, y luego comparar las diferencias entre las dos representaciones.\n",
        "\n",
        "Si es necesario eliminar en alguno de los casos las \"stop-words\"."
      ],
      "metadata": {
        "id": "igZZJjjxpkkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "bBQkxh09cL-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords_esp = set(stopwords.words('spanish'))"
      ],
      "metadata": {
        "id": "bIJHTqqkf_kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PROYECTO-DE-LEY-TURISMO-SOCIAL-2004.pdf-----Con-CountVectorizer-------------------------------------------------------------------------\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "with open('/content/PROYECTO DE LEY TURISMO SOCIAL 2004.pdf', 'rb'):\n",
        "    lector = PyPDF2.PdfReader('PROYECTO DE LEY TURISMO SOCIAL 2004.pdf')\n",
        "\n",
        "texto = \"\"\n",
        "\n",
        "for i in range(len(lector.pages)):\n",
        "    pagina = lector.pages[i]\n",
        "    texto += pagina.extract_text()\n",
        "\n",
        "#Tokenizo el texto y elimino las stopwords, luego genero el texto sin las stopwords:\n",
        "palabras = nltk.word_tokenize(texto)\n",
        "palabras_sin_stopwords = [palabra for palabra in palabras if palabra.lower() not in stopwords_esp]\n",
        "texto_sin_stopwords = ' '.join(palabras_sin_stopwords)\n",
        "\n",
        "#Segmentación del texto sin stopwords:\n",
        "corpus = texto_sin_stopwords.split(\".\")\n",
        "\n",
        "#Instancia de CountVectorizer:\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(\"Vectores de características:\\n\", X.toarray())\n",
        "\n",
        "print(\"\\nPalabras del vocabulario:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "print('\\nVectores con palabras como columnas:')\n",
        "print(df)\n",
        "\n",
        "# Webscrapping-Ministerio-De-Turismo----------TfidfVectorizer------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "RHz4mnpnq1Wj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}